# CBAM: Convolutional Block Attention Module
This repository contains an implementation of the Convolution Block Attention Module (CBAM) using the TensorFlow framework. CBAM is a powerful attention mechanism designed to enhance the performance of convolutional neural networks by adaptively recalibrating feature maps.

**What is CBAM?**

CBAM is a straightforward yet highly effective attention module tailored for feed-forward convolutional neural networks. It operates by sequentially deriving attention maps along two distinct dimensions: channel and spatial. By doing so, CBAM allows the network to focus on relevant features, improving both the discriminative power and generalization capabilities.

**Key Features:**

Channel Attention: Identifies and amplifies significant channels within the feature map, enabling the network to prioritize relevant information.

Spatial Attention: Captures spatial dependencies across feature maps, facilitating the localization of important regions.

Adaptive Feature Refinement: The attention maps generated by CBAM are multiplicatively combined with the input feature map, facilitating adaptive feature refinement tailored to the task at hand.

**Seamless Integration and Wide Applicability:**

Because CBAM is a lightweight and general module, it seamlessly integrates into any CNN architecture with negligible overheads and is end-to-end trainable along with base CNNs. Extensive experiments conducted on ImageNet-1K, MS COCO detection, and VOC 2007 detection datasets validate CBAM's consistent improvements in classification and detection performances across various models, demonstrating its wide applicability.

**CBAM:**
![CBAM](https://github.com/AlirezaFBabaei/CBAM-Convolutional-Block-Attention-Module/assets/50638445/23b0bfa3-a8ad-4914-9a1a-982142594cd1)

**Channel Attention Module:**
![cam](https://github.com/AlirezaFBabaei/CBAM-Convolutional-Block-Attention-Module/assets/50638445/a7073675-e3d8-432a-a702-92fa8c7788b5)

**Spatial Attention Module:**
![sam](https://github.com/AlirezaFBabaei/CBAM-Convolutional-Block-Attention-Module/assets/50638445/ac186c0a-d6ca-43d8-be81-4a571412be0f)

**CBAM integrated with a ResBlock in ResNet:**
![CBAM+ResUnet](https://github.com/AlirezaFBabaei/CBAM-Convolutional-Block-Attention-Module/assets/50638445/2cebdc36-d903-47dd-bbb7-b1cce8b3ab9f)
