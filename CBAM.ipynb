{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "UqfcHZnz9Uo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qRW5-VGz8PwJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Input\n",
        "from tensorflow.keras.layers import Activation, Concatenate, Conv2D, Multiply"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Channel Attention Module"
      ],
      "metadata": {
        "id": "GDo0XtAp9Z8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Channel_Attention_Module(input, ratio=16):\n",
        "\n",
        "  b, _, _, channel = input.shape\n",
        "\n",
        "  # Shared MLP\n",
        "  l1 = Dense(channel//ratio, activation='relu', use_bias=False)\n",
        "  l2 = Dense(channel, use_bias=False)\n",
        "\n",
        "  # Global Average Pooling\n",
        "  avepool = GlobalAveragePooling2D()(input)\n",
        "  a = l1(avepool)\n",
        "  a = l2(a)\n",
        "\n",
        "  # Global Max Pooling\n",
        "  maxpool = GlobalMaxPooling2D()(input)\n",
        "  m = l1(maxpool)\n",
        "  m = l2(m)\n",
        "\n",
        "  # Add Average and Max Pooling\n",
        "  concat = a + m\n",
        "  concat = Activation('sigmoid')(concat)\n",
        "\n",
        "  output = Multiply()([input, concat])\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "WjuYM44V9T4p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial Attention Module"
      ],
      "metadata": {
        "id": "ehlWXnQB_z8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Spatial_Attention_Module(input):\n",
        "\n",
        "  # Average Pooling\n",
        "  avepool = tf.reduce_mean(input, axis=-1)\n",
        "  avepool = tf.expand_dims(input, axis=-1)\n",
        "\n",
        "  # Max Pooling\n",
        "  maxpool = tf.reduce_max(input, axis=-1)\n",
        "  maxpool = tf.expand_dims(input, axis=-1)\n",
        "\n",
        "  # Concatenate Average and Max Pooling\n",
        "  concat = Concatenate()([avepool, maxpool])\n",
        "\n",
        "  conv = Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
        "\n",
        "  output = Multiply()([input, conv])\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "SsXQlINC_4Mo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBAM"
      ],
      "metadata": {
        "id": "LgxF3YKdD7N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CBAM(input):\n",
        "  attention = Channel_Attention_Module(input)\n",
        "  attention = Spatial_Attention_Module(attention)\n",
        "\n",
        "  return attention"
      ],
      "metadata": {
        "id": "Szjs9ysFD9Gn"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}